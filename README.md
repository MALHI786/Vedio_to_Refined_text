# ğŸ¬ AI Video to Fluent Text

> A multi-modal AI system that converts spoken English from videos into fluent, professional text using transformer-based neural networks.

## ğŸ¯ Project Overview

This system:
1. **Extracts audio** from uploaded videos
2. **Converts speech to text** using Whisper (Neural Network)
3. **Improves English** (grammar, fluency, professionalism)
4. **Displays** the final polished script

## ğŸ—ï¸ Architecture

```
Video Upload â†’ Audio Extraction â†’ Speech-to-Text â†’ Text Improvement â†’ Fluent Output
     â”‚              â”‚                   â”‚                 â”‚              â”‚
   FFmpeg        FFmpeg            Whisper AI      Transformer      Final Text
                                   (OpenAI)         Model
```

## ğŸ“‚ Project Structure

```
ai-video-to-fluent-text/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI server
â”‚   â””â”€â”€ pipeline.py          # Complete AI pipeline
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html           # Web UI
â”‚   â”œâ”€â”€ styles.css           # Styling
â”‚   â””â”€â”€ script.js            # Frontend logic
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ audio_extractor.py   # FFmpeg audio extraction
â”‚   â”œâ”€â”€ speech_to_text.py    # Whisper transcription
â”‚   â”œâ”€â”€ text_cleaner.py      # Text preprocessing
â”‚   â””â”€â”€ text_improver.py     # Grammar correction
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_pipeline.py     # Test scripts
â”œâ”€â”€ models/                  # Cached AI models
â”œâ”€â”€ datasets/                # Training/test data
â”œâ”€â”€ uploads/                 # Temporary files
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md
```

## ğŸ› ï¸ Tech Stack

- **Speech-to-Text**: OpenAI Whisper
- **Text Improvement**: Transformer-based grammar correction
- **Backend**: FastAPI (Python)
- **Frontend**: HTML/CSS/JavaScript
- **Audio Processing**: FFmpeg

## ğŸš€ Quick Start

```bash
# 1. Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run the backend
cd backend
uvicorn main:app --reload

# 4. Open frontend
# Open frontend/index.html in browser
```

## ğŸ’» Local Execution (CLI)

For quick local testing without the web interface:

```bash
# 1. Run the automatic local script (Windows)
./run_local.bat

# 2. Or run manually via Python
python scripts/run_pipeline.py --video attendy.mp4 --out output
```

## ğŸ“Š Neural Networks Used

1. **Whisper** - Transformer-based ASR (Automatic Speech Recognition)
2. **T5/Grammar Correction Model** - Text-to-Text Transformer for fluency

## ğŸ‘¨â€ğŸ’» Author
Salman Malhi
